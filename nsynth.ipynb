{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRmlJYze_29V"
      },
      "source": [
        "Copyright 2017 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZKppJ2kBbxj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install magenta\n",
        "print('Installing Magenta...\\n')\n",
        "!pip install -qU magenta\n",
        "print('Installing ffmpeg...\\n')\n",
        "!echo \"Yes\" | apt-get install ffmpeg > /dev/null\n",
        "\n",
        "\n",
        "print('Downloading Pretrained Models...\\n')\n",
        "# Copy checkpoints from google cloud\n",
        "# Copying 1GB, takes a minute\n",
        "print('Getting Instruments Model...\\n')\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar /content/\n",
        "print('Getting Voices Model...\\n')\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/nsynth/wavenet-voice-ckpt.tar.gz /content/\n",
        "!cd /content/\n",
        "!tar -xvf wavenet-ckpt.tar > /dev/null\n",
        "!tar -xvf wavenet-voice-ckpt.tar.gz > /dev/null\n",
        "\n",
        "\n",
        "print('Importing Modules...\\n')\n",
        "# Load modules and helper functions\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio\n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import files\n",
        "from magenta.models.nsynth import utils\n",
        "from magenta.models.nsynth.wavenet import fastgen\n",
        "from note_seq.notebook_utils import colab_play as play"
      ],
      "metadata": {
        "id": "q7r2dbpJf3ZV",
        "outputId": "6b8b9d51-48f0-41db-aef4-d0b79bd32c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Magenta...\n",
            "\n",
            "Installing ffmpeg...\n",
            "\n",
            "Downloading Pretrained Models...\n",
            "\n",
            "Getting Instruments Model...\n",
            "\n",
            "Getting Voices Model...\n",
            "\n",
            "Importing Modules...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSXXL26bLDCy",
        "outputId": "062b7ffd-abeb-4366-c05e-3fb0b6b076f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model pretrained on Voices.\n"
          ]
        }
      ],
      "source": [
        "#@title Choose a Model { vertical-output: true, run: \"auto\" }\n",
        "Model = \"Voices\" #@param [\"Instruments\", \"Voices\"] {type:\"string\"}\n",
        "ckpts = {'Instruments': '/content/wavenet-ckpt/model.ckpt-200000',\n",
        "         'Voices': '/content/wavenet-voice-ckpt/model.ckpt-200000'}\n",
        "\n",
        "ckpt_path = ckpts[Model]\n",
        "print('Using model pretrained on %s.' % Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnSCiX0kA2-5"
      },
      "outputs": [],
      "source": [
        "#@title Set Sound Length (in Seconds) { vertical-output: true, run: \"auto\" }\n",
        "Length = 4.0 #@param {type:\"number\"}\n",
        "SR = 16000\n",
        "SAMPLE_LENGTH = int(SR * Length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPwQYyYgBkdp"
      },
      "outputs": [],
      "source": [
        "def get_audio_list(file_list, audio_list):\n",
        "  get_name = lambda f: os.path.splitext(os.path.basename(f))[0]\n",
        "  names = [get_name(f) for f in file_list]  \n",
        "  # Pad and peak normalize\n",
        "  for i in range(len(audio_list)):\n",
        "    audio_list[i] = audio_list[i] / np.abs(audio_list[i]).max()\n",
        "\n",
        "    if len(audio_list[i]) < SAMPLE_LENGTH:\n",
        "      padding = SAMPLE_LENGTH - len(audio_list[i])\n",
        "      audio_list[i] = np.pad(audio_list[i], (0, padding), 'constant')\n",
        "\n",
        "  audio_list = np.array(audio_list)\n",
        "  return audio_list, names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSr-7vuH_29l"
      },
      "outputs": [],
      "source": [
        "def gen_encodings(audio_list, names):\n",
        "  audio = np.array(audio_list)\n",
        "  z = fastgen.encode(audio, ckpt_path, SAMPLE_LENGTH)\n",
        "  print('Encoded %d files' % z.shape[0])\n",
        "\n",
        "\n",
        "  # Start with reconstructions\n",
        "  z_list = [z_ for z_ in z]\n",
        "  name_list = ['recon_' + name_ for name_ in names]\n",
        "\n",
        "  # Add all the mean interpolations\n",
        "  n = len(names)\n",
        "  for i in range(n - 1):\n",
        "    for j in range(i + 1, n):\n",
        "      new_z = (z[i] + z[j]) / 2.0\n",
        "      new_name = 'interp_' + names[i] + '_X_'+ names[j]\n",
        "      z_list.append(new_z)\n",
        "      name_list.append(new_name)\n",
        "\n",
        "  print(\"%d total: %d reconstructions and %d interpolations\" % (len(name_list), n, len(name_list) - n))\n",
        "\n",
        "  return z_list, name_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKR6CGUe_290"
      },
      "source": [
        "For fun, we can take a look at the encoding of our audio files. They are compressed representations of the audio but have some structure in their own right, (16 numbers, kind of like 16 channels of audio, so there are 16 different lines, colors are arbitrary). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cawft23_290"
      },
      "outputs": [],
      "source": [
        "# #@title Visualize Audio and Encoding { vertical-output: true, run: \"auto\" }\n",
        "# SoundFile = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "# file_number = SoundFile\n",
        "\n",
        "# try:\n",
        "#   print(names[file_number])\n",
        "#   play(audio_list[file_number], sample_rate=SR)\n",
        "#   # fig, axs = plt.subplots(2, 1, figsize=(12, 10))\n",
        "#   plt.figure()\n",
        "#   plt.plot(audio_list[file_number])\n",
        "#   plt.title('Audio Signal')\n",
        "\n",
        "#   plt.figure()\n",
        "#   plt.plot(z_list[file_number])\n",
        "#   plt.title('NSynth Encoding')\n",
        "# except Exception as e:\n",
        "#   print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Eh71eovH4NZ"
      },
      "outputs": [],
      "source": [
        "def synthesize_interpolations(z_list, name_list, directory):\n",
        "  print('Total Iterations to Complete: %d\\n' % SAMPLE_LENGTH)\n",
        "\n",
        "  encodings = np.array(z_list)\n",
        "  save_paths = [directory + name + '.wav' for name in name_list]\n",
        "  fastgen.synthesize(encodings,\n",
        "                    save_paths=save_paths,\n",
        "                    checkpoint_path=ckpt_path,\n",
        "                    samples_per_save=int(SAMPLE_LENGTH / 10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_input_paths(dir_path):\n",
        "  data_temp = []\n",
        "  for file in os.scandir(dir_path):\n",
        "    data_temp.append([file.path, file.name])\n",
        "\n",
        "  return pd.DataFrame(data_temp, columns=[\"relative_path\", \"filename\"])"
      ],
      "metadata": {
        "id": "Sazca46YoYfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = get_input_paths(\"drive/MyDrive/GMMGroup/Ingredient_One\")\n",
        "df_testest = get_input_paths(\"drive/MyDrive/GMMGroup/Ingredient_Two\")\n",
        "len(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1b9a27-fd42-4c5a-8ad2-9dada5ca7633",
        "id": "n4y6WQLSoYfI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df_test)):\n",
        "  print(df_test.relative_path[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "490b19c9-1898-4df1-8161-0822037b922f",
        "id": "EEtpv9i9oYfI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/GMMGroup/testUpload/s01 (1).wav\n",
            "drive/MyDrive/GMMGroup/testUpload/s20 (4).wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in range(len(df_test)):\n",
        "  file_list, audio_list = [], []\n",
        "  audio1 = utils.load_audio(df_test.relative_path[i], sample_length=SAMPLE_LENGTH, sr=SR)\n",
        "  audio2 = utils.load_audio(df_testest.relative_path[i], sample_length=SAMPLE_LENGTH, sr=SR)\n",
        "  file_list.append(df_test.relative_path[i])\n",
        "  file_list.append(df_testest.relative_path[i])\n",
        "  audio_list.append(audio1)\n",
        "  audio_list.append(audio2)\n",
        "  a_list, names= get_audio_list(file_list, audio_list)\n",
        "  z_list, name_list = gen_encodings(a_list, names)\n",
        "  synthesize_interpolations(z_list, name_list, \"drive/MyDrive/GMMGroup/OutputSounds/\")"
      ],
      "metadata": {
        "id": "bFxJJhQsoYfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VmIIqE3Uo-08"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nsynth.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}